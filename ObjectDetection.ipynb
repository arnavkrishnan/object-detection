{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnavkrishnan/object-detection/blob/main/ObjectDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9eLQFUiGBj0"
      },
      "source": [
        "<font color=Red><h1><b>\n",
        "REMINDER: Make a copy of this notebook if you want to save your work.\n",
        "</b></h1></font>\n",
        "\n",
        "<font color=DarkGray><h3><b>\n",
        "To do this, you can go to *File > Save a Copy in Drive* and it should open a new tab with your copy.\n",
        "</b></h3></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploying Your Object Detection App!"
      ],
      "metadata": {
        "id": "6sUQx9mI1H-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20%20Object%20Detection%20(Autonomous%20Vehicles)/object-detection-image.png)"
      ],
      "metadata": {
        "id": "EWAefWyvXgiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our model trained and set up, we can deploy it as a full scale application to the web! While your site is running, you'll be able to use it on your laptop or computer or share it with friends! We'll be using [Streamlit](https://www.streamlit.io/), a library of website objects and methods that allows us to quickly build a site."
      ],
      "metadata": {
        "id": "mQOQJORZXjKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1. Streamlit - Deploying your model to the web\n",
        "Today we will be using Streamlit, a framework to easily build web applications, to deploy our models to the web so that they can be shared to the web!\n",
        "\n",
        "Take a moment to look through examples of websites built with Streamlit [here](https://streamlit.io/gallery?category=favorites). As a class, choose your favorite and answer the following **questions:**\n",
        "* Who is this application for?\n",
        "* How does the user input data - are these intuitive ways of interacting with the app?\n",
        "* What does the application do with the data?\n",
        "* Evaluate the ease of use and look of the application.\n",
        "\n",
        "Now that we’ve seen what is possible with Streamlit, let’s try to deploy our **Object Detection model** to the web!"
      ],
      "metadata": {
        "id": "bkVsPLnNXtSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run this to download data and prepare our environment! { display-mode: \"form\" }\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import gdown\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers import concatenate, add\n",
        "from keras.models import Model\n",
        "import struct\n",
        "import cv2\n",
        "from copy import deepcopy\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "class HiddenPrints:\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout\n",
        "\n",
        "with HiddenPrints():\n",
        "    # Prepare data\n",
        "    DATA_ROOT = '/content/data'\n",
        "    os.makedirs(DATA_ROOT, exist_ok=True)\n",
        "\n",
        "    !pip -q install streamlit\n",
        "    !pip -q install pyngrok\n",
        "\n",
        "    from pyngrok import ngrok\n",
        "    import streamlit\n",
        "\n",
        "    # image_url = 'https://drive.google.com/uc?id=12ZpZ5H0kJIkWk6y4ktGfqR5OTKofL7qw'\n",
        "    # image_path = os.path.join(DATA_ROOT, 'image.jpg')\n",
        "    # gdown.download(image_url, image_path, True)\n",
        "    !wget -O /content/data/image.jpg \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20%20Object%20Detection%20(Autonomous%20Vehicles)/image.jpg\"\n",
        "\n",
        "    # image2_url = 'https://drive.google.com/uc?id=1_WpFbGEuS2r19UeP6wekbcF0kb-0nH18'\n",
        "    # image2_path = os.path.join(DATA_ROOT, 'image2.jpg')\n",
        "    # gdown.download(image2_url, image2_path, True)\n",
        "    !wget -O /content/data/image2.jpg \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20%20Object%20Detection%20(Autonomous%20Vehicles)/image2.jpg\"\n",
        "\n",
        "    # video_url = 'https://drive.google.com/uc?id=1xFGjpzhZVYtNor9hJevvxysGESZJIMDz'\n",
        "    # video_path = os.path.join(DATA_ROOT, 'video1.mp4')\n",
        "    # gdown.download(video_url, video_path, True)\n",
        "    !wget -O /content/data/video1.mp4 \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20%20Object%20Detection%20(Autonomous%20Vehicles)/6.mp4\"\n",
        "\n",
        "    # model_url = 'https://drive.google.com/uc?id=19XKJWMKDfDlag2MR8ofjwvxhtr9BxqqN'\n",
        "    # model_path = os.path.join(DATA_ROOT, 'yolo_weights.h5')\n",
        "    # gdown.download(model_url, model_path, True)\n",
        "    !wget -O /content/data/yolo_weights.h5 \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20%20Object%20Detection%20(Autonomous%20Vehicles)/yolo.h5\"\n",
        "\n",
        "\n",
        "\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
        "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
        "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
        "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
        "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
        "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
        "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
        "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
        "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
        "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "\n",
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "\n",
        "        return self.label\n",
        "\n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "\n",
        "        return self.score\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "\n",
        "    return float(intersect) / union\n",
        "\n",
        "def preprocess_input(image_pil, net_h, net_w):\n",
        "    image = np.asarray(image_pil)\n",
        "    new_h, new_w, _ = image.shape\n",
        "    # print(\"net:\", net_h, net_w)\n",
        "    # print(\"old:\",new_h, new_w)\n",
        "    # determine the new size of the image\n",
        "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
        "        new_h = (new_h * net_w)/new_w\n",
        "        new_w = net_w\n",
        "    else:\n",
        "        new_w = (new_w * net_h)/new_h\n",
        "        new_h = net_h\n",
        "    new_w = int(new_w)\n",
        "    new_h = int(new_h)\n",
        "    # print(\"new:\",int(new_h), int(new_w))\n",
        "    # resize the image to the new size\n",
        "    #resized = cv2.resize(image[:,:,::-1]/255., (int(new_w), int(new_h)))\n",
        "    resized = cv2.resize(image/255., (int(new_w), int(new_h)))\n",
        "\n",
        "    # embed the image into the standard letter box\n",
        "    # print(\"dims:\",int((net_h-new_h)//2), int((net_h+new_h)//2), int((net_w-new_w)//2), int((net_w+new_w)//2))\n",
        "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
        "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
        "    new_image = np.expand_dims(new_image, 0)\n",
        "    # print(new_image.shape)\n",
        "\n",
        "\n",
        "    return new_image\n",
        "\n",
        "\n",
        "def decode_netout(netout_, obj_thresh, anchors_, image_h, image_w, net_h, net_w):\n",
        "    netout_all = deepcopy(netout_)\n",
        "    boxes_all = []\n",
        "    for i in range(len(netout_all)):\n",
        "      netout = netout_all[i][0]\n",
        "      anchors = anchors_[i]\n",
        "\n",
        "      grid_h, grid_w = netout.shape[:2]\n",
        "      nb_box = 3\n",
        "      netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "      nb_class = netout.shape[-1] - 5\n",
        "\n",
        "      boxes = []\n",
        "\n",
        "      netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "      netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "      netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "      netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "      for i in range(grid_h*grid_w):\n",
        "          row = i // grid_w\n",
        "          col = i % grid_w\n",
        "\n",
        "          for b in range(nb_box):\n",
        "              # 4th element is objectness score\n",
        "              objectness = netout[row][col][b][4]\n",
        "              #objectness = netout[..., :4]\n",
        "              # last elements are class probabilities\n",
        "              classes = netout[row][col][b][5:]\n",
        "\n",
        "              if((classes <= obj_thresh).all()): continue\n",
        "\n",
        "              # first 4 elements are x, y, w, and h\n",
        "              x, y, w, h = netout[row][col][b][:4]\n",
        "\n",
        "              x = (col + x) / grid_w # center position, unit: image width\n",
        "              y = (row + y) / grid_h # center position, unit: image height\n",
        "              w = anchors[b][0] * np.exp(w) / net_w # unit: image width\n",
        "              h = anchors[b][1] * np.exp(h) / net_h # unit: image height\n",
        "\n",
        "              box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "              #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
        "\n",
        "              boxes.append(box)\n",
        "\n",
        "      boxes_all += boxes\n",
        "\n",
        "    # Correct boxes\n",
        "    boxes_all = correct_yolo_boxes(boxes_all, image_h, image_w, net_h, net_w)\n",
        "\n",
        "    return boxes_all\n",
        "\n",
        "def correct_yolo_boxes(boxes_, image_h, image_w, net_h, net_w):\n",
        "    boxes = deepcopy(boxes_)\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "        new_w = net_w\n",
        "        new_h = (image_h*net_w)/image_w\n",
        "    else:\n",
        "        new_h = net_w\n",
        "        new_w = (image_w*net_h)/image_h\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        "    return boxes\n",
        "\n",
        "def do_nms(boxes_, nms_thresh, obj_thresh):\n",
        "    boxes = deepcopy(boxes_)\n",
        "    if len(boxes) > 0:\n",
        "        num_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    for c in range(num_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0\n",
        "\n",
        "    new_boxes = []\n",
        "    for box in boxes:\n",
        "        label = -1\n",
        "\n",
        "        for i in range(num_class):\n",
        "            if box.classes[i] > obj_thresh:\n",
        "                label = i\n",
        "                # print(\"{}: {}, ({}, {})\".format(labels[i], box.classes[i]*100, box.xmin, box.ymin))\n",
        "                box.label = label\n",
        "                box.score = box.classes[i]\n",
        "                new_boxes.append(box)\n",
        "\n",
        "    return new_boxes\n",
        "\n",
        "\n",
        "from PIL import ImageDraw, ImageFont\n",
        "import colorsys\n",
        "\n",
        "def draw_boxes(image_, boxes, labels):\n",
        "    image = image_.copy()\n",
        "    image_w, image_h = image.size\n",
        "    font = ImageFont.truetype(font='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf',\n",
        "                    size=np.floor(3e-2 * image_h + 0.5).astype('int32'))\n",
        "    thickness = (image_w + image_h) // 300\n",
        "\n",
        "    # Generate colors for drawing bounding boxes.\n",
        "    hsv_tuples = [(x / len(labels), 1., 1.)\n",
        "                  for x in range(len(labels))]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(\n",
        "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "    np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
        "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
        "    np.random.seed(None)  # Reset seed to default.\n",
        "\n",
        "    for i, box in reversed(list(enumerate(boxes))):\n",
        "        c = box.get_label()\n",
        "        predicted_class = labels[c]\n",
        "        score = box.get_score()\n",
        "        top, left, bottom, right = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "\n",
        "        label = '{} {:.2f}'.format(predicted_class, score)\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        label_size = draw.textbbox((0,0),label, font)\n",
        "        label_size = (label_size[2], label_size[3])\n",
        "\n",
        "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
        "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
        "        bottom = min(image_h, np.floor(bottom + 0.5).astype('int32'))\n",
        "        right = min(image_w, np.floor(right + 0.5).astype('int32'))\n",
        "        print(label, (left, top), (right, bottom))\n",
        "\n",
        "        if top - label_size[1] >= 0:\n",
        "            text_origin = np.array([left, top - label_size[1]])\n",
        "        else:\n",
        "            text_origin = np.array([left, top + 1])\n",
        "\n",
        "        # My kingdom for a good redistributable image drawing library.\n",
        "        if right > left and bottom > top:\n",
        "          # proceed to draw the box\n",
        "          draw.rectangle([left, top, right, bottom], outline=colors[c], width=thickness)\n",
        "        else:\n",
        "          print(f\"Invalid box: {(left, top, right, bottom)}\")\n",
        "\n",
        "\n",
        "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
        "        #draw.text(text_origin, label, fill=(0, 0, 0))\n",
        "        del draw\n",
        "    return image\n",
        "\n",
        "def launch_website():\n",
        "  try:\n",
        "    if ngrok.get_tunnels():\n",
        "      ngrok.kill()\n",
        "    tunnel = ngrok.connect()\n",
        "\n",
        "    print(\"Click this link to try your web app:\")\n",
        "    print(tunnel.public_url)\n",
        "\n",
        "    !streamlit run --server.port 80 app.py >/dev/null # Connect to the URL through Port 80 (>/dev/null hides outputs)\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "    ngrok.kill()"
      ],
      "metadata": {
        "id": "E1cGZ5zWfgld"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title custom domain\n",
        "#@markdown my static domain from a free account in ngrok\n",
        "from google.colab import userdata\n",
        "static_domain = userdata.get('static_domain')\n",
        "import os\n",
        "\n",
        "def launch_website():\n",
        "    try:\n",
        "        # Kill any running ngrok processes\n",
        "        os.system(\"pkill -f ngrok\")\n",
        "\n",
        "        # Start ngrok with your static domain\n",
        "        ngrok_command = f\"ngrok http --domain={static_domain}.ngrok-free.app 80\"\n",
        "        os.system(f\"{ngrok_command} &\")\n",
        "\n",
        "        print(\"Click this link to try your web app:\")\n",
        "        print(f\"https://{static_domain}.ngrok-free.app\")\n",
        "\n",
        "        # Run Streamlit app\n",
        "        os.system(\"streamlit run --server.port 80 app.py >/dev/null\")  # Connect to the URL through Port 80 (>/dev/null hides outputs)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        os.system(\"pkill -f ngrok\")\n"
      ],
      "metadata": {
        "id": "4bNP-atd5LNa"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's make sure that we are using our GPU! <br> This block of code should output `Found GPU at: /device:GPU:0`. <br> If not, go to your `Runtime` tab, and `Change Runtime`.\n",
        "- Select a T4 GPU or TPU under the Hardware Accelerator section!"
      ],
      "metadata": {
        "id": "7s1sO0FM7pbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('No GPU Found! D:')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "uvUx1cAG7rX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acec65a-4710-4e49-9e69-3d65c4782c14"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When dealing with Streamlit and web development, we begin to work with **file management**. In Python web development, such as Flask and Streamlit, we use a central Python file to launch our app. In this case, we will use `app.py`.\n",
        "```\n",
        "app.py\n",
        "```"
      ],
      "metadata": {
        "id": "a644whDkX8Iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Streamlit, we can build a simple webapp like so:"
      ],
      "metadata": {
        "id": "RtZHuP-cdJ0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "%%writefile app.py\n",
        "```\n",
        "The `%%writefile` command writes to a file, either overwriting what's already there or creating it if it doesn't already exist. Everything that follows the rest of this block of code will be written to `app.py`.\n",
        "\n",
        "In this case, we use this command to create our `app.py` file, which you can check by clicking on the folder on the left sidebar."
      ],
      "metadata": {
        "id": "KdOdJ-ODdahf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "st.title('Hello World!')"
      ],
      "metadata": {
        "id": "lTPwvXvcdPh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab80147-8461-4b93-bc0c-0665c3060f06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To initiate our `app.py`, we employ both Streamlit and ngrok in tandem. ngrok serves as a hosting service that enables us to establish secure tunnels to our localhost, making our local server accessible over the internet. Streamlit, on the other hand, is a powerful library designed to turn Python scripts into interactive web applications easily. By integrating Streamlit with ngrok, we create a bridge that connects our Python application to the web, allowing external access.\n",
        "\n",
        "<br> To get access to our ngrok server, we need to sign up on their website and get a unique **authentication token**."
      ],
      "metadata": {
        "id": "WHaXdm2yne2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=SlateGrey><h2><b>\n",
        "Use [these](https://drive.google.com/file/d/12zwuOuKh91VSHIHS-6S4ADF4HLC2wKJq/view?usp=sharing) instructions to create a ngrok account and get your authtoken!\n",
        "</b></h2></font>\n",
        "\n",
        "<font color=DarkGray><h3><b>\n",
        "Paste your authtoken below next to `!ngrok authtoken`!\n",
        "</b></h3></font>"
      ],
      "metadata": {
        "id": "lxdAMUKRn5mj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9Fbg8jwYn5mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158ff478-8746-4bd8-fa68-3a1cce8d2df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "authtoken - \n",
            "\n",
            "USAGE:\n",
            "  ngrok authtoken TOKEN [flags]\n",
            "\n",
            "COMMANDS: \n",
            "  config          update or migrate ngrok's configuration file\n",
            "  http            start an HTTP tunnel\n",
            "  tcp             start a TCP tunnel\n",
            "  tunnel          start a tunnel for use with a tunnel-group backend\n",
            "\n",
            "EXAMPLES: \n",
            "  ngrok http 80                                                 # secure public URL for port 80 web server\n",
            "  ngrok http --url baz.ngrok.dev 8080                           # port 8080 available at baz.ngrok.dev\n",
            "  ngrok tcp 22                                                  # tunnel arbitrary TCP traffic to port 22\n",
            "  ngrok http 80 --oauth=google --oauth-allow-email=foo@foo.com  # secure your app with oauth\n",
            "\n",
            "Paid Features: \n",
            "  ngrok http 80 --url mydomain.com                              # run ngrok with your own custom domain\n",
            "  ngrok http 80 --cidr-allow 2600:8c00::a03c:91ee:fe69:9695/32  # run ngrok with IP policy restrictions\n",
            "  Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Flags:\n",
            "  -h, --help      help for ngrok\n",
            "\n",
            "Use \"ngrok [command] --help\" for more information about a command.\n",
            "\n",
            "ERROR:  accepts 1 arg(s), received 0\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken # Place Your Authtoken Here (without the #)!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#secret"
      ],
      "metadata": {
        "id": "un55c8hC3i90"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title mine\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get the auth token\n",
        "authtoken = userdata.get('authtoken')\n",
        "\n",
        "# Run ngrok with the token using shell command\n",
        "!ngrok authtoken {authtoken}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKS7R6H4vnBw",
        "outputId": "078f0c3e-02f7-4fd5-9df7-4da593d28256"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can launch our website through the `launch_website()` function, which connects our ngrok token by building a 'tunnel' to our Streamlit code."
      ],
      "metadata": {
        "id": "oTuX65aQpS3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code now to use our function. Click on the link, and hit the `Visit Site` button to view your site!"
      ],
      "metadata": {
        "id": "XUwUJ7Mtq8eD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "launch_website()"
      ],
      "metadata": {
        "id": "sNTZdEYBiWb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a271c078-370b-489f-ec99-4f177ab5b24d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Click this link to try your web app:\n",
            "https://45ee-34-23-192-39.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the question remains, how do we connect our computer vision models to our website?"
      ],
      "metadata": {
        "id": "eLr1ITQlrMuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2. Connecting our model to our website"
      ],
      "metadata": {
        "id": "K9e8EYA0rRdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that earlier, we wrote the function `detect_image()` with the arguments `image_pil, obj_thresh=0.4, nms_thresh=0.45, darknet=darknet, net_h=416, net_w=416, anchors=anchors, labels=labels`. <br><br> `anchors` and `labels` are variables that had been defined previously in the last notebook. Keep in mind that our server only has access to the files that we write to. In this case, we only have `app.py`! <br><br> This may have been what our `detect_image` function looked like:\n",
        "```python\n",
        "def detect_image(image_pil, obj_thresh = 0.4, nms_thresh = 0.45, darknet=darknet, net_h=416, net_w=416, anchors=anchors, labels=labels):\n",
        "\n",
        "  # Preprocessing\n",
        "  image_w, image_h = image_pil.size\n",
        "  new_image = preprocess_input(image_pil, net_h, net_w)\n",
        "\n",
        "  # DarkNet\n",
        "  yolo_outputs = darknet.predict(new_image)\n",
        "\n",
        "  # Decode the output of the network\n",
        "  boxes = decode_netout(yolo_outputs, obj_thresh, anchors, image_h, image_w, net_h, net_w)\n",
        "\n",
        "  # Suppress non-maximal boxes\n",
        "  boxes = do_nms(boxes, nms_thresh, obj_thresh)\n",
        "\n",
        "  # Draw bounding boxes on the image using labels\n",
        "  image_detect = draw_boxes(image_pil, boxes, labels)\n",
        "\n",
        "  return image_detect\n",
        "```\n"
      ],
      "metadata": {
        "id": "XEccUL6QrceV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, notice how many variables and imports we needed. <br><br>For `yolo_outputs = darknet.predict(new_image)`, we needed to import the entire darknet model (which our current website doesn't have access to!), the anchors, labels, etc. <br><br>In order to get this all working in our `app.py`, we would have to paste all of these variables in, including ***ALL*** of the hidden functions we used in our last notebook! For the imports alone, it would look something like this:"
      ],
      "metadata": {
        "id": "93yervB-tUEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click the dropdown to display all the code you'd be pasting in\n",
        "%%writefile app.py\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers import concatenate, add\n",
        "from keras.models import Model\n",
        "import struct\n",
        "import cv2\n",
        "from copy import deepcopy\n",
        "\n",
        "anchors = [[[116,90], [156,198], [373,326]], [[30,61], [62,45], [59,119]], [[10,13], [16,30], [33,23]]]\n",
        "\n",
        "DATA_ROOT = '/content/data'\n",
        "\n",
        "model_path = os.path.join(DATA_ROOT, 'yolo_weights.h5')\n",
        "\n",
        "darknet = tf.keras.models.load_model(model_path, compile=False)\n",
        "\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
        "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
        "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
        "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
        "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
        "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
        "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
        "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
        "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
        "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "\n",
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "\n",
        "        return self.label\n",
        "\n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "\n",
        "        return self.score\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "\n",
        "    return float(intersect) / union\n",
        "\n",
        "def preprocess_input(image_pil, net_h, net_w):\n",
        "    image = np.asarray(image_pil)\n",
        "    # Remove the alpha channel if it exists\n",
        "    if image.shape[2] == 4:\n",
        "        image = image[:, :, :3]\n",
        "\n",
        "    new_h, new_w, _ = image.shape\n",
        "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
        "        new_h = (new_h * net_w)/new_w\n",
        "        new_w = net_w\n",
        "    else:\n",
        "        new_w = (new_w * net_h)/new_h\n",
        "        new_h = net_h\n",
        "\n",
        "    new_w = int(new_w)\n",
        "    new_h = int(new_h)\n",
        "\n",
        "    resized = cv2.resize(image/255., (int(new_w), int(new_h)))\n",
        "\n",
        "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
        "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
        "    new_image = np.expand_dims(new_image, 0)\n",
        "\n",
        "    return new_image\n",
        "\n",
        "\n",
        "def decode_netout(netout_, obj_thresh, anchors_, image_h, image_w, net_h, net_w):\n",
        "    netout_all = deepcopy(netout_)\n",
        "    boxes_all = []\n",
        "    for i in range(len(netout_all)):\n",
        "      netout = netout_all[i][0]\n",
        "      anchors = anchors_[i]\n",
        "\n",
        "      grid_h, grid_w = netout.shape[:2]\n",
        "      nb_box = 3\n",
        "      netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "      nb_class = netout.shape[-1] - 5\n",
        "\n",
        "      boxes = []\n",
        "\n",
        "      netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "      netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "      netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "      netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "      for i in range(grid_h*grid_w):\n",
        "          row = i // grid_w\n",
        "          col = i % grid_w\n",
        "\n",
        "          for b in range(nb_box):\n",
        "              # 4th element is objectness score\n",
        "              objectness = netout[row][col][b][4]\n",
        "              #objectness = netout[..., :4]\n",
        "              # last elements are class probabilities\n",
        "              classes = netout[row][col][b][5:]\n",
        "\n",
        "              if((classes <= obj_thresh).all()): continue\n",
        "\n",
        "              # first 4 elements are x, y, w, and h\n",
        "              x, y, w, h = netout[row][col][b][:4]\n",
        "\n",
        "              x = (col + x) / grid_w # center position, unit: image width\n",
        "              y = (row + y) / grid_h # center position, unit: image height\n",
        "              w = anchors[b][0] * np.exp(w) / net_w # unit: image width\n",
        "              h = anchors[b][1] * np.exp(h) / net_h # unit: image height\n",
        "\n",
        "              box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "              #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
        "\n",
        "              boxes.append(box)\n",
        "\n",
        "      boxes_all += boxes\n",
        "\n",
        "    # Correct boxes\n",
        "    boxes_all = correct_yolo_boxes(boxes_all, image_h, image_w, net_h, net_w)\n",
        "\n",
        "    return boxes_all\n",
        "\n",
        "def correct_yolo_boxes(boxes_, image_h, image_w, net_h, net_w):\n",
        "    boxes = deepcopy(boxes_)\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "        new_w = net_w\n",
        "        new_h = (image_h*net_w)/image_w\n",
        "    else:\n",
        "        new_h = net_w\n",
        "        new_w = (image_w*net_h)/image_h\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        "    return boxes\n",
        "\n",
        "def do_nms(boxes_, nms_thresh, obj_thresh):\n",
        "    boxes = deepcopy(boxes_)\n",
        "    if len(boxes) > 0:\n",
        "        num_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    for c in range(num_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0\n",
        "\n",
        "    new_boxes = []\n",
        "    for box in boxes:\n",
        "        label = -1\n",
        "\n",
        "        for i in range(num_class):\n",
        "            if box.classes[i] > obj_thresh:\n",
        "                label = i\n",
        "                # print(\"{}: {}, ({}, {})\".format(labels[i], box.classes[i]*100, box.xmin, box.ymin))\n",
        "                box.label = label\n",
        "                box.score = box.classes[i]\n",
        "                new_boxes.append(box)\n",
        "\n",
        "    return new_boxes\n",
        "\n",
        "\n",
        "from PIL import ImageDraw, ImageFont\n",
        "import colorsys\n",
        "\n",
        "def draw_boxes(image_, boxes, labels):\n",
        "    image = image_.copy()\n",
        "    image_w, image_h = image.size\n",
        "    font = ImageFont.truetype(font='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf',\n",
        "                    size=np.floor(3e-2 * image_h + 0.5).astype('int32'))\n",
        "    thickness = (image_w + image_h) // 300\n",
        "\n",
        "    # Generate colors for drawing bounding boxes.\n",
        "    hsv_tuples = [(x / len(labels), 1., 1.)\n",
        "                  for x in range(len(labels))]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(\n",
        "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "    np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
        "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
        "    np.random.seed(None)  # Reset seed to default.\n",
        "\n",
        "    for i, box in reversed(list(enumerate(boxes))):\n",
        "        c = box.get_label()\n",
        "        predicted_class = labels[c]\n",
        "        score = box.get_score()\n",
        "        top, left, bottom, right = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "\n",
        "        label = '{} {:.2f}'.format(predicted_class, score)\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        label_size = draw.textbbox((0,0),label, font)\n",
        "        label_size = (label_size[2], label_size[3])\n",
        "\n",
        "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
        "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
        "        bottom = min(image_h, np.floor(bottom + 0.5).astype('int32'))\n",
        "        right = min(image_w, np.floor(right + 0.5).astype('int32'))\n",
        "        print(label, (left, top), (right, bottom))\n",
        "\n",
        "        if top - label_size[1] >= 0:\n",
        "            text_origin = np.array([left, top - label_size[1]])\n",
        "        else:\n",
        "            text_origin = np.array([left, top + 1])\n",
        "\n",
        "        # My kingdom for a good redistributable image drawing library.\n",
        "        for i in range(thickness):\n",
        "            draw.rectangle(\n",
        "                [left + i, top + i, right - i, bottom - i],\n",
        "                outline=colors[c])\n",
        "        draw.rectangle(\n",
        "            [tuple(text_origin), tuple(text_origin + label_size)],\n",
        "            fill=colors[c])\n",
        "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
        "        #draw.text(text_origin, label, fill=(0, 0, 0))\n",
        "        del draw\n",
        "    return image\n",
        "\n",
        "def detect_image(image_pil, obj_thresh = 0.4, nms_thresh = 0.45, darknet=darknet, net_h=416, net_w=416, anchors=anchors, labels=labels):\n",
        "\n",
        "  # Preprocessing\n",
        "  image_w, image_h = image_pil.size\n",
        "  new_image = preprocess_input(image_pil, net_h, net_w)\n",
        "\n",
        "  # DarkNet\n",
        "  yolo_outputs = darknet.predict(new_image)\n",
        "\n",
        "  # Decode the output of the network\n",
        "  boxes = decode_netout(yolo_outputs, obj_thresh, anchors, image_h, image_w, net_h, net_w)\n",
        "\n",
        "  # Suppress non-maximal boxes\n",
        "  boxes = do_nms(boxes, nms_thresh, obj_thresh)\n",
        "\n",
        "  # Draw bounding boxes on the image using labels\n",
        "  image_detect = draw_boxes(image_pil, boxes, labels)\n",
        "\n",
        "  return image_detect\n",
        "\n",
        "# Streamlit app\n",
        "st.title('Object Detection')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cw-j4MRut6zB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8794580-040d-4257-d6fb-e9047bebe303"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with our tiny\n",
        "```python\n",
        "import streamlit as st\n",
        "\n",
        "st.title('Hello World!')\n",
        "```\n",
        "at the end!"
      ],
      "metadata": {
        "id": "46Yk8HrTuRcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead, we can write all our code to another file called **`utils.py`**.<br> This way, we can instead add this to the top of our **`app.py`** file.\n",
        "```python\n",
        "from utils.py import *\n",
        "```\n",
        "The `import *` imports all variables and functions from our **`utils.py`** file. You can also use\n",
        "```python\n",
        "from utils.py import anchors, model_path\n",
        "```\n",
        "if you wanted to import only **`anchors`** and **`model_path`**, but there are a lot of functions and variables to list we want to use. Now, our code might look like this for **`app.py`**:\n",
        "```python\n",
        "from utils.py import *\n",
        "import streamlit as st\n",
        "\n",
        "st.title('Hello World!')\n",
        "```"
      ],
      "metadata": {
        "id": "BHzHxg53usUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise: Write to a **`utils.py`** file!"
      ],
      "metadata": {
        "id": "Eyl4wvC6voMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile"
      ],
      "metadata": {
        "id": "x5J2RvEQurSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5890d9-5c4f-4246-ebc2-9e47c5d9b64e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: %%writefile is a cell magic, but the cell body is empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instructor Solution\n",
        "%%writefile utils.py\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers import concatenate, add\n",
        "from keras.models import Model\n",
        "import struct\n",
        "import cv2\n",
        "from copy import deepcopy\n",
        "\n",
        "anchors = [[[116,90], [156,198], [373,326]], [[30,61], [62,45], [59,119]], [[10,13], [16,30], [33,23]]]\n",
        "\n",
        "DATA_ROOT = '/content/data'\n",
        "\n",
        "model_path = os.path.join(DATA_ROOT, 'yolo_weights.h5')\n",
        "\n",
        "darknet = tf.keras.models.load_model(model_path, compile=False)\n",
        "\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
        "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
        "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
        "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
        "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
        "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
        "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
        "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
        "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
        "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "\n",
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "\n",
        "        return self.label\n",
        "\n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "\n",
        "        return self.score\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "\n",
        "    return float(intersect) / union\n",
        "\n",
        "def preprocess_input(image_pil, net_h, net_w):\n",
        "    image = np.asarray(image_pil)\n",
        "    # Remove the alpha channel if it exists\n",
        "    if image.shape[2] == 4:\n",
        "        image = image[:, :, :3]\n",
        "\n",
        "    new_h, new_w, _ = image.shape\n",
        "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
        "        new_h = (new_h * net_w)/new_w\n",
        "        new_w = net_w\n",
        "    else:\n",
        "        new_w = (new_w * net_h)/new_h\n",
        "        new_h = net_h\n",
        "\n",
        "    new_w = int(new_w)\n",
        "    new_h = int(new_h)\n",
        "\n",
        "    resized = cv2.resize(image/255., (int(new_w), int(new_h)))\n",
        "\n",
        "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
        "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
        "    new_image = np.expand_dims(new_image, 0)\n",
        "\n",
        "    return new_image\n",
        "\n",
        "\n",
        "def decode_netout(netout_, obj_thresh, anchors_, image_h, image_w, net_h, net_w):\n",
        "    netout_all = deepcopy(netout_)\n",
        "    boxes_all = []\n",
        "    for i in range(len(netout_all)):\n",
        "      netout = netout_all[i][0]\n",
        "      anchors = anchors_[i]\n",
        "\n",
        "      grid_h, grid_w = netout.shape[:2]\n",
        "      nb_box = 3\n",
        "      netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "      nb_class = netout.shape[-1] - 5\n",
        "\n",
        "      boxes = []\n",
        "\n",
        "      netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "      netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "      netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "      netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "      for i in range(grid_h*grid_w):\n",
        "          row = i // grid_w\n",
        "          col = i % grid_w\n",
        "\n",
        "          for b in range(nb_box):\n",
        "              # 4th element is objectness score\n",
        "              objectness = netout[row][col][b][4]\n",
        "              #objectness = netout[..., :4]\n",
        "              # last elements are class probabilities\n",
        "              classes = netout[row][col][b][5:]\n",
        "\n",
        "              if((classes <= obj_thresh).all()): continue\n",
        "\n",
        "              # first 4 elements are x, y, w, and h\n",
        "              x, y, w, h = netout[row][col][b][:4]\n",
        "\n",
        "              x = (col + x) / grid_w # center position, unit: image width\n",
        "              y = (row + y) / grid_h # center position, unit: image height\n",
        "              w = anchors[b][0] * np.exp(w) / net_w # unit: image width\n",
        "              h = anchors[b][1] * np.exp(h) / net_h # unit: image height\n",
        "\n",
        "              box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "              #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
        "\n",
        "              boxes.append(box)\n",
        "\n",
        "      boxes_all += boxes\n",
        "\n",
        "    # Correct boxes\n",
        "    boxes_all = correct_yolo_boxes(boxes_all, image_h, image_w, net_h, net_w)\n",
        "\n",
        "    return boxes_all\n",
        "\n",
        "def correct_yolo_boxes(boxes_, image_h, image_w, net_h, net_w):\n",
        "    boxes = deepcopy(boxes_)\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "        new_w = net_w\n",
        "        new_h = (image_h*net_w)/image_w\n",
        "    else:\n",
        "        new_h = net_w\n",
        "        new_w = (image_w*net_h)/image_h\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        "    return boxes\n",
        "\n",
        "def do_nms(boxes_, nms_thresh, obj_thresh):\n",
        "    boxes = deepcopy(boxes_)\n",
        "    if len(boxes) > 0:\n",
        "        num_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    for c in range(num_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0\n",
        "\n",
        "    new_boxes = []\n",
        "    for box in boxes:\n",
        "        label = -1\n",
        "\n",
        "        for i in range(num_class):\n",
        "            if box.classes[i] > obj_thresh:\n",
        "                label = i\n",
        "                # print(\"{}: {}, ({}, {})\".format(labels[i], box.classes[i]*100, box.xmin, box.ymin))\n",
        "                box.label = label\n",
        "                box.score = box.classes[i]\n",
        "                new_boxes.append(box)\n",
        "\n",
        "    return new_boxes\n",
        "\n",
        "\n",
        "from PIL import ImageDraw, ImageFont\n",
        "import colorsys\n",
        "\n",
        "def draw_boxes(image_, boxes, labels):\n",
        "    image = image_.copy()\n",
        "    image_w, image_h = image.size\n",
        "    font = ImageFont.truetype(font='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf',\n",
        "                    size=np.floor(3e-2 * image_h + 0.5).astype('int32'))\n",
        "    thickness = (image_w + image_h) // 300\n",
        "\n",
        "    # Generate colors for drawing bounding boxes.\n",
        "    hsv_tuples = [(x / len(labels), 1., 1.)\n",
        "                  for x in range(len(labels))]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(\n",
        "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "    np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
        "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
        "    np.random.seed(None)  # Reset seed to default.\n",
        "\n",
        "    for i, box in reversed(list(enumerate(boxes))):\n",
        "        c = box.get_label()\n",
        "        predicted_class = labels[c]\n",
        "        score = box.get_score()\n",
        "        top, left, bottom, right = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "\n",
        "        label = '{} {:.2f}'.format(predicted_class, score)\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        label_size = draw.textbbox((0,0),label, font)\n",
        "        label_size = (label_size[2], label_size[3])\n",
        "\n",
        "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
        "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
        "        bottom = min(image_h, np.floor(bottom + 0.5).astype('int32'))\n",
        "        right = min(image_w, np.floor(right + 0.5).astype('int32'))\n",
        "        print(label, (left, top), (right, bottom))\n",
        "\n",
        "        if top - label_size[1] >= 0:\n",
        "            text_origin = np.array([left, top - label_size[1]])\n",
        "        else:\n",
        "            text_origin = np.array([left, top + 1])\n",
        "\n",
        "        # My kingdom for a good redistributable image drawing library.\n",
        "        for i in range(thickness):\n",
        "            draw.rectangle(\n",
        "                [left + i, top + i, right - i, bottom - i],\n",
        "                outline=colors[c])\n",
        "        draw.rectangle(\n",
        "            [tuple(text_origin), tuple(text_origin + label_size)],\n",
        "            fill=colors[c])\n",
        "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
        "        #draw.text(text_origin, label, fill=(0, 0, 0))\n",
        "        del draw\n",
        "    return image\n",
        "\n",
        "def detect_image(image_pil, obj_thresh = 0.4, nms_thresh = 0.45, darknet=darknet, net_h=416, net_w=416, anchors=anchors, labels=labels):\n",
        "\n",
        "  # Preprocessing\n",
        "  image_w, image_h = image_pil.size\n",
        "  new_image = preprocess_input(image_pil, net_h, net_w)\n",
        "\n",
        "  # DarkNet\n",
        "  yolo_outputs = darknet.predict(new_image)\n",
        "\n",
        "  # Decode the output of the network\n",
        "  boxes = decode_netout(yolo_outputs, obj_thresh, anchors, image_h, image_w, net_h, net_w)\n",
        "\n",
        "  # Suppress non-maximal boxes\n",
        "  boxes = do_nms(boxes, nms_thresh, obj_thresh)\n",
        "\n",
        "  # Draw bounding boxes on the image using labels\n",
        "  image_detect = draw_boxes(image_pil, boxes, labels)\n",
        "\n",
        "  return image_detect"
      ],
      "metadata": {
        "id": "M1fDdjYAvx8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d529b25f-e907-413e-9e72-19f70a9392ee"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fix NoneType Error\n",
        "%%writefile utils.py\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers import concatenate, add\n",
        "from keras.models import Model\n",
        "import struct\n",
        "import cv2\n",
        "from copy import deepcopy\n",
        "\n",
        "anchors = [[[116,90], [156,198], [373,326]], [[30,61], [62,45], [59,119]], [[10,13], [16,30], [33,23]]]\n",
        "\n",
        "DATA_ROOT = '/content/data'\n",
        "\n",
        "model_path = os.path.join(DATA_ROOT, 'yolo_weights.h5')\n",
        "\n",
        "darknet = tf.keras.models.load_model(model_path, compile=False)\n",
        "\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
        "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
        "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
        "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
        "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
        "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
        "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
        "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
        "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
        "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
        "\n",
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "\n",
        "        return self.label\n",
        "\n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "\n",
        "        return self.score\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "\n",
        "    return float(intersect) / union\n",
        "\n",
        "def preprocess_input(image_pil, net_h, net_w):\n",
        "    image = np.asarray(image_pil)\n",
        "    # Remove the alpha channel if it exists\n",
        "    if image.shape[2] == 4:\n",
        "        image = image[:, :, :3]\n",
        "\n",
        "    new_h, new_w, _ = image.shape\n",
        "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
        "        new_h = (new_h * net_w)/new_w\n",
        "        new_w = net_w\n",
        "    else:\n",
        "        new_w = (new_w * net_h)/new_h\n",
        "        new_h = net_h\n",
        "\n",
        "    new_w = int(new_w)\n",
        "    new_h = int(new_h)\n",
        "\n",
        "    resized = cv2.resize(image/255., (int(new_w), int(new_h)))\n",
        "\n",
        "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
        "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
        "    new_image = np.expand_dims(new_image, 0)\n",
        "\n",
        "    return new_image\n",
        "\n",
        "\n",
        "def decode_netout(netout_, obj_thresh, anchors_, image_h, image_w, net_h, net_w):\n",
        "    netout_all = deepcopy(netout_)\n",
        "    boxes_all = []\n",
        "    for i in range(len(netout_all)):\n",
        "      netout = netout_all[i][0]\n",
        "      anchors = anchors_[i]\n",
        "\n",
        "      grid_h, grid_w = netout.shape[:2]\n",
        "      nb_box = 3\n",
        "      netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "      nb_class = netout.shape[-1] - 5\n",
        "\n",
        "      boxes = []\n",
        "\n",
        "      netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "      netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "      netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "      netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "      for i in range(grid_h*grid_w):\n",
        "          row = i // grid_w\n",
        "          col = i % grid_w\n",
        "\n",
        "          for b in range(nb_box):\n",
        "              # 4th element is objectness score\n",
        "              objectness = netout[row][col][b][4]\n",
        "              #objectness = netout[..., :4]\n",
        "              # last elements are class probabilities\n",
        "              classes = netout[row][col][b][5:]\n",
        "\n",
        "              if((classes <= obj_thresh).all()): continue\n",
        "\n",
        "              # first 4 elements are x, y, w, and h\n",
        "              x, y, w, h = netout[row][col][b][:4]\n",
        "\n",
        "              x = (col + x) / grid_w # center position, unit: image width\n",
        "              y = (row + y) / grid_h # center position, unit: image height\n",
        "              w = anchors[b][0] * np.exp(w) / net_w # unit: image width\n",
        "              h = anchors[b][1] * np.exp(h) / net_h # unit: image height\n",
        "\n",
        "              box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "              #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
        "\n",
        "              boxes.append(box)\n",
        "\n",
        "      boxes_all += boxes\n",
        "\n",
        "    # Correct boxes\n",
        "    boxes_all = correct_yolo_boxes(boxes_all, image_h, image_w, net_h, net_w)\n",
        "\n",
        "    return boxes_all\n",
        "\n",
        "def correct_yolo_boxes(boxes_, image_h, image_w, net_h, net_w):\n",
        "    boxes = deepcopy(boxes_)\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "        new_w = net_w\n",
        "        new_h = (image_h*net_w)/image_w\n",
        "    else:\n",
        "        new_h = net_w\n",
        "        new_w = (image_w*net_h)/image_h\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        "    return boxes\n",
        "\n",
        "def do_nms(boxes_, nms_thresh, obj_thresh):\n",
        "    boxes = deepcopy(boxes_)\n",
        "    if len(boxes) > 0:\n",
        "        num_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    for c in range(num_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0\n",
        "\n",
        "    new_boxes = []\n",
        "    for box in boxes:\n",
        "        label = -1\n",
        "\n",
        "        for i in range(num_class):\n",
        "            if box.classes[i] > obj_thresh:\n",
        "                label = i\n",
        "                # print(\"{}: {}, ({}, {})\".format(labels[i], box.classes[i]*100, box.xmin, box.ymin))\n",
        "                box.label = label\n",
        "                box.score = box.classes[i]\n",
        "                new_boxes.append(box)\n",
        "\n",
        "    return new_boxes\n",
        "\n",
        "\n",
        "from PIL import ImageDraw, ImageFont\n",
        "import colorsys\n",
        "\n",
        "def draw_boxes(image_, boxes, labels):\n",
        "    image = image_.copy()\n",
        "    image_w, image_h = image.size\n",
        "    font = ImageFont.truetype(font='/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf',\n",
        "                    size=np.floor(3e-2 * image_h + 0.5).astype('int32'))\n",
        "    thickness = (image_w + image_h) // 300\n",
        "\n",
        "    # Generate colors for drawing bounding boxes.\n",
        "    hsv_tuples = [(x / len(labels), 1., 1.)\n",
        "                  for x in range(len(labels))]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(\n",
        "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "    np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
        "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
        "    np.random.seed(None)  # Reset seed to default.\n",
        "\n",
        "    if boxes is None:\n",
        "      return image;\n",
        "      st.write(\"No objects detected.\")\n",
        "\n",
        "    for i, box in reversed(list(enumerate(boxes))):\n",
        "        c = box.get_label()\n",
        "        predicted_class = labels[c]\n",
        "        score = box.get_score()\n",
        "        top, left, bottom, right = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "\n",
        "        label = '{} {:.2f}'.format(predicted_class, score)\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        label_size = draw.textbbox((0,0),label, font)\n",
        "        label_size = (label_size[2], label_size[3])\n",
        "\n",
        "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
        "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
        "        bottom = min(image_h, np.floor(bottom + 0.5).astype('int32'))\n",
        "        right = min(image_w, np.floor(right + 0.5).astype('int32'))\n",
        "        print(label, (left, top), (right, bottom))\n",
        "\n",
        "        if top - label_size[1] >= 0:\n",
        "            text_origin = np.array([left, top - label_size[1]])\n",
        "        else:\n",
        "            text_origin = np.array([left, top + 1])\n",
        "\n",
        "        # My kingdom for a good redistributable image drawing library.\n",
        "        for i in range(thickness):\n",
        "            draw.rectangle(\n",
        "                [left + i, top + i, right - i, bottom - i],\n",
        "                outline=colors[c])\n",
        "        draw.rectangle(\n",
        "            [tuple(text_origin), tuple(text_origin + label_size)],\n",
        "            fill=colors[c])\n",
        "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
        "        #draw.text(text_origin, label, fill=(0, 0, 0))\n",
        "        del draw\n",
        "    return image\n",
        "\n",
        "def detect_image(image_pil, obj_thresh = 0.4, nms_thresh = 0.45, darknet=darknet, net_h=416, net_w=416, anchors=anchors, labels=labels):\n",
        "\n",
        "  # Preprocessing\n",
        "  image_w, image_h = image_pil.size\n",
        "  new_image = preprocess_input(image_pil, net_h, net_w)\n",
        "\n",
        "  # DarkNet\n",
        "  yolo_outputs = darknet.predict(new_image)\n",
        "\n",
        "  # Decode the output of the network\n",
        "  boxes = decode_netout(yolo_outputs, obj_thresh, anchors, image_h, image_w, net_h, net_w)\n",
        "\n",
        "  # Suppress non-maximal boxes\n",
        "  boxes = do_nms(boxes, nms_thresh, obj_thresh)\n",
        "\n",
        "  # Draw bounding boxes on the image using labels\n",
        "  image_detect = draw_boxes(image_pil, boxes, labels)\n",
        "\n",
        "  return image_detect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_sGHOZKt5sH",
        "outputId": "67ce0952-7124-4563-ca47-99a06a8c31b1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we want to create a Streamlit object for our site to use to upload images! You can do so by using the following:\n",
        "```python\n",
        "uploaded_file = st.file_uploader(\"Prompt\", type=[\"jpg\", \"png\"])\n",
        "```\n",
        "This will display a button with the \"Prompt\" string, and allows the users to input files of type **`jpg, png`**, which are common image file types."
      ],
      "metadata": {
        "id": "T5NdFwnQwC4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3. Putting it all together"
      ],
      "metadata": {
        "id": "3F3VN1uGxYV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's rewrite our **`app.py`** file!\n",
        "\n",
        "*Tip*: When we add in the `%%writefile` magic command, Colab removes all syntax highlighting, which makes the code a lot harder to read! If you'd like, you can comment out that `%%writefile` line by adding a `#` at the beginning to restore the syntax highlighting as you edit. Make sure you remove that `#` before you run this, so that your `app.py` file is actually overwritten!"
      ],
      "metadata": {
        "id": "i7vZShA5xcDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from utils import *\n",
        "from PIL import Image\n",
        "\n",
        "# Your Streamlit app goes here!\n",
        "st.title('Name')\n",
        "\n",
        "uploaded_file = # Fill this in!\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = # Use Image.open to open the image\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True) # use_column_width is optional, just helps for Display\n",
        "\n",
        "    # Fill in the rest of this! Your instructor will give hints.\n",
        "    # Feel free to Google, explore, and look through the streamlit documentation for details"
      ],
      "metadata": {
        "id": "55Li2rTvwCIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98670ba2-58f3-44c3-83a1-f7665f807861"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a basic toolbox to work with, but look things up to explore!\n",
        "```python\n",
        "#Text\n",
        "st.write(\"text\")\n",
        "\n",
        "#Title\n",
        "st.title('title')\n",
        "\n",
        "#Header\n",
        "st.header('header')\n",
        "\n",
        "#Slider\n",
        "value = st.slider('variable')\n",
        "\n",
        "#Table\n",
        "st.table(dataframe) # Replace with your own Pandas dataframe variable\n",
        "\n",
        "#Matplotlib Figure\n",
        "st.pyplot(fig) # Replace with your own Matplotlib figure variable\n",
        "\n",
        "#Image\n",
        "st.image(image, caption='Image Caption') # Replace with your own image variable\n",
        "\n",
        "#Button\n",
        "pressed = st.button('Button Name')\n",
        "\n",
        "#Checkbox\n",
        "checked = st.checkbox('Checkbox Name')\n",
        "\n",
        "#File Input\n",
        "uploaded_file = st.file_uploader(\"Upload File\")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    pass #Do something here!\n",
        "```"
      ],
      "metadata": {
        "id": "3zxF14zkybTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instructor Solution (Feel free to point them in the right direction here, but give them options for creativity)\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from utils import *\n",
        "from PIL import Image\n",
        "\n",
        "# Streamlit app\n",
        "st.title('Object Detection')\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file) # Use Image.open to open the image\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True) # use_column_width is optional, just helps for display\n",
        "    st.write(\"\")\n",
        "    st.write(\"Detecting...\")\n",
        "\n",
        "    detected_image = detect_image(image)\n",
        "\n",
        "    st.image(detected_image, caption='Detected Image.', use_column_width=True)"
      ],
      "metadata": {
        "id": "CBXzTP4tg0wj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336f6e19-6c36-424e-fffa-3e785c1f71d6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finally, let's launch our website again :)"
      ],
      "metadata": {
        "id": "3biMvChLy0-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "launch_website()"
      ],
      "metadata": {
        "id": "qgjMp0jzy0bX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75533d38-c321-4fd4-95fe-9cf4e6112f1c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Click this link to try your web app:\n",
            "https://vervet-infinite-reliably.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try testing different images for your object detection app by searching for any images on Google! Here's one below for reference (right-click and hit Save As... and upload the image to your app to test!):\n",
        "\n",
        "![](https://www.stockvault.net/data/2016/03/12/187548/preview16.jpg)"
      ],
      "metadata": {
        "id": "d88M3LRtxAUD"
      }
    }
  ]
}